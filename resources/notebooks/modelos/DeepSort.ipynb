{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPjJ7LPqO7ODb5141BWlhhW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"wQG--2a4c_le"},"outputs":[],"source":["import time\n","import logging\n","from collections.abc import Iterable\n","\n","import cv2\n","import numpy as np\n","\n","from deep_sort_realtime.deep_sort import nn_matching\n","from deep_sort_realtime.deep_sort.detection import Detection\n","from deep_sort_realtime.deep_sort.tracker import Tracker\n","from deep_sort_realtime.utils.nms import non_max_suppression\n","\n","logger = logging.getLogger(__name__)\n","\n","EMBEDDER_CHOICES = [\n","    \"mobilenet\",\n","    \"torchreid\",\n","    \"clip_RN50\",\n","    \"clip_RN101\",\n","    \"clip_RN50x4\",\n","    \"clip_RN50x16\",\n","    \"clip_ViT-B/32\",\n","    \"clip_ViT-B/16\",\n","]\n","\n","\n","class DeepSort(object):\n","    def __init__(\n","        self,\n","        max_iou_distance=0.7,\n","        max_age=30,\n","        n_init=3,\n","        nms_max_overlap=1.0,\n","        max_cosine_distance=0.2,\n","        nn_budget=None,\n","        gating_only_position=False,\n","        override_track_class=None,\n","        embedder=\"mobilenet\",\n","        half=True,\n","        bgr=True,\n","        embedder_gpu=True,\n","        embedder_model_name=None,\n","        embedder_wts=None,\n","        polygon=False,\n","        today=None,\n","    ):\n","        \"\"\"\n","\n","        Parameters\n","        ----------\n","        max_iou_distance : Optional[float] = 0.7\n","            Gating threshold on IoU. Associations with cost larger than this value are\n","            disregarded. Argument for deep_sort_realtime.deep_sort.tracker.Tracker.\n","        max_age : Optional[int] = 30\n","            Maximum number of missed misses before a track is deleted. Argument for deep_sort_realtime.deep_sort.tracker.Tracker.\n","        n_init : int\n","            Number of frames that a track remains in initialization phase. Defaults to 3. Argument for deep_sort_realtime.deep_sort.tracker.Tracker.\n","        nms_max_overlap : Optional[float] = 1.0\n","            Non-maxima suppression threshold: Maximum detection overlap, if is 1.0, nms will be disabled\n","        max_cosine_distance : Optional[float] = 0.2\n","            Gating threshold for cosine distance\n","        nn_budget :  Optional[int] = None\n","            Maximum size of the appearance descriptors, if None, no budget is enforced\n","        gating_only_position : Optional[bool]\n","            Used during gating, comparing KF predicted and measured states. If True, only the x, y position of the state distribution is considered during gating. Defaults to False, where x,y, aspect ratio and height will be considered.\n","        override_track_class : Optional[object] = None\n","            Giving this will override default Track class, this must inherit Track. Argument for deep_sort_realtime.deep_sort.tracker.Tracker.\n","        embedder : Optional[str] = 'mobilenet'\n","            Whether to use in-built embedder or not. If None, then embeddings must be given during update.\n","            Choice of ['mobilenet', 'torchreid', 'clip_RN50', 'clip_RN101', 'clip_RN50x4', 'clip_RN50x16', 'clip_ViT-B/32', 'clip_ViT-B/16']\n","        half : Optional[bool] = True\n","            Whether to use half precision for deep embedder (applicable for mobilenet only)\n","        bgr : Optional[bool] = True\n","            Whether frame given to embedder is expected to be BGR or not (RGB)\n","        embedder_gpu: Optional[bool] = True\n","            Whether embedder uses gpu or not\n","        embedder_model_name: Optional[str] = None\n","            Only used when embedder=='torchreid'. This provides which model to use within torchreid library. Check out torchreid's model zoo.\n","        embedder_wts: Optional[str] = None\n","            Optional specification of path to embedder's model weights. Will default to looking for weights in `deep_sort_realtime/embedder/weights`. If deep_sort_realtime is installed as a package and CLIP models is used as embedder, best to provide path.\n","        polygon: Optional[bool] = False\n","            Whether detections are polygons (e.g. oriented bounding boxes)\n","        today: Optional[datetime.date]\n","            Provide today's date, for naming of tracks. Argument for deep_sort_realtime.deep_sort.tracker.Tracker.\n","        \"\"\"\n","        self.nms_max_overlap = nms_max_overlap\n","        metric = nn_matching.NearestNeighborDistanceMetric(\n","            \"cosine\", max_cosine_distance, nn_budget\n","        )\n","        self.tracker = Tracker(\n","            metric,\n","            max_iou_distance=max_iou_distance,\n","            max_age=max_age,\n","            n_init=n_init,\n","            override_track_class=override_track_class,\n","            today=today,\n","            gating_only_position=gating_only_position,\n","        )\n","\n","        if embedder is not None:\n","            if embedder not in EMBEDDER_CHOICES:\n","                raise Exception(f\"Embedder {embedder} is not a valid choice.\")\n","            if embedder == \"mobilenet\":\n","                from deep_sort_realtime.embedder.embedder_pytorch import (\n","                    MobileNetv2_Embedder as Embedder,\n","                )\n","\n","                self.embedder = Embedder(\n","                    half=half,\n","                    max_batch_size=16,\n","                    bgr=bgr,\n","                    gpu=embedder_gpu,\n","                    model_wts_path=embedder_wts,\n","                )\n","            elif embedder == 'torchreid':\n","                from deep_sort_realtime.embedder.embedder_pytorch import TorchReID_Embedder as Embedder\n","\n","                self.embedder = Embedder(\n","                    bgr=bgr,\n","                    gpu=embedder_gpu,\n","                    model_name=embedder_model_name,\n","                    model_wts_path=embedder_wts,\n","                )\n","\n","            elif embedder.startswith('clip_'):\n","                from deep_sort_realtime.embedder.embedder_clip import (\n","                    Clip_Embedder as Embedder,\n","                )\n","\n","                model_name = \"_\".join(embedder.split(\"_\")[1:])\n","                self.embedder = Embedder(\n","                    model_name=model_name,\n","                    model_wts_path=embedder_wts,\n","                    max_batch_size=16,\n","                    bgr=bgr,\n","                    gpu=embedder_gpu,\n","                )\n","\n","        else:\n","            self.embedder = None\n","        self.polygon = polygon\n","        logger.info(\"DeepSort Tracker initialised\")\n","        logger.info(f\"- max age: {max_age}\")\n","        logger.info(f\"- appearance threshold: {max_cosine_distance}\")\n","        logger.info(\n","            f'- nms threshold: {\"OFF\" if self.nms_max_overlap==1.0 else self.nms_max_overlap }'\n","        )\n","        logger.info(f\"- max num of appearance features: {nn_budget}\")\n","        logger.info(\n","            f'- overriding track class : {\"No\" if override_track_class is None else \"Yes\"}'\n","        )\n","        logger.info(f'- today given : {\"No\" if today is None else \"Yes\"}')\n","        logger.info(f'- in-build embedder : {\"No\" if self.embedder is None else \"Yes\"}')\n","        logger.info(f'- polygon detections : {\"No\" if polygon is False else \"Yes\"}')\n","\n","    def update_tracks(self, raw_detections, embeds=None, frame=None, today=None, others=None, instance_masks=None):\n","\n","        \"\"\"Run multi-target tracker on a particular sequence.\n","\n","        Parameters\n","        ----------\n","        raw_detections (horizontal bb) : List[ Tuple[ List[float or int], float, str ] ]\n","            List of detections, each in tuples of ( [left,top,w,h] , confidence, detection_class)\n","        raw_detections (polygon) : List[ List[float], List[int or str], List[float] ]\n","            List of Polygons, Classes, Confidences. All 3 sublists of the same length. A polygon defined as a ndarray-like [x1,y1,x2,y2,...].\n","        embeds : Optional[ List[] ] = None\n","            List of appearance features corresponding to detections\n","        frame : Optional [ np.ndarray ] = None\n","            if embeds not given, Image frame must be given here, in [H,W,C].\n","        today: Optional[datetime.date]\n","            Provide today's date, for naming of tracks\n","        others: Optional[ List ] = None\n","            Other things associated to detections to be stored in tracks, usually, could be corresponding segmentation mask, other associated values, etc. Currently others is ignored with polygon is True.\n","        instance_masks: Optional [ List ] = None\n","            Instance masks corresponding to detections. If given, they are used to filter out background and only use foreground for apperance embedding. Expects numpy boolean mask matrix.\n","\n","        Returns\n","        -------\n","        list of track objects (Look into track.py for more info or see \"main\" section below in this script to see simple example)\n","\n","        \"\"\"\n","\n","        if embeds is None:\n","            if self.embedder is None:\n","                raise Exception(\n","                    \"Embedder not created during init so embeddings must be given now!\"\n","                )\n","            if frame is None:\n","                raise Exception(\"either embeddings or frame must be given!\")\n","\n","        assert isinstance(raw_detections,Iterable)\n","\n","        if len(raw_detections) > 0:\n","            if not self.polygon:\n","                assert len(raw_detections[0][0])==4\n","                raw_detections = [d for d in raw_detections if d[0][2] > 0 and d[0][3] > 0]\n","\n","                if embeds is None:\n","                    embeds = self.generate_embeds(frame, raw_detections, instance_masks=instance_masks)\n","\n","                # Proper deep sort detection objects that consist of bbox, confidence and embedding.\n","                detections = self.create_detections(raw_detections, embeds, instance_masks=instance_masks, others=others)\n","            else:\n","                polygons, bounding_rects = self.process_polygons(raw_detections[0])\n","\n","                if embeds is None:\n","                    embeds = self.generate_embeds_poly(frame, polygons, bounding_rects)\n","\n","                # Proper deep sort detection objects that consist of bbox, confidence and embedding.\n","                detections = self.create_detections_poly(\n","                    raw_detections, embeds, bounding_rects,\n","                )\n","        else:\n","            detections = []\n","\n","        # Run non-maxima suppression.\n","        boxes = np.array([d.ltwh for d in detections])\n","        scores = np.array([d.confidence for d in detections])\n","        if self.nms_max_overlap < 1.0:\n","            # nms_tic = time.perf_counter()\n","            indices = non_max_suppression(boxes, self.nms_max_overlap, scores)\n","            # nms_toc = time.perf_counter()\n","            # logger.debug(f'nms time: {nms_toc-nms_tic}s')\n","            detections = [detections[i] for i in indices]\n","\n","        # Update tracker.\n","        self.tracker.predict()\n","        self.tracker.update(detections, today=today)\n","\n","        return self.tracker.tracks\n","\n","    def refresh_track_ids(self):\n","        self.tracker._next_id\n","\n","    def generate_embeds(self, frame, raw_dets, instance_masks=None):\n","        crops, cropped_inst_masks = self.crop_bb(frame, raw_dets, instance_masks=instance_masks)\n","        if cropped_inst_masks is not None:\n","            masked_crops = []\n","            for crop, mask in zip(crops, cropped_inst_masks):\n","                masked_crop = np.zeros_like(crop)\n","                masked_crop = masked_crop + np.array([123.675, 116.28, 103.53], dtype=crop.dtype)\n","                masked_crop[mask] = crop[mask]\n","                masked_crops.append(masked_crop)\n","            return self.embedder.predict(masked_crops)\n","        else:\n","            return self.embedder.predict(crops)\n","\n","    def generate_embeds_poly(self, frame, polygons, bounding_rects):\n","        crops = self.crop_poly_pad_black(frame, polygons, bounding_rects)\n","        return self.embedder.predict(crops)\n","\n","    def create_detections(self, raw_dets, embeds, instance_masks=None, others=None):\n","        detection_list = []\n","        for i, (raw_det, embed) in enumerate(zip(raw_dets, embeds)):\n","            detection_list.append(\n","                Detection(\n","                    raw_det[0],\n","                    raw_det[1],\n","                    embed,\n","                    class_name=raw_det[2] if len(raw_det)==3 else None,\n","                    instance_mask = instance_masks[i] if isinstance(instance_masks, Iterable) else instance_masks,\n","                    others = others[i] if isinstance(others, Iterable) else others,\n","                )\n","            )  # raw_det = [bbox, conf_score, class]\n","        return detection_list\n","\n","    def create_detections_poly(self, dets, embeds, bounding_rects):\n","        detection_list = []\n","        dets.extend([embeds, bounding_rects])\n","        for raw_polygon, cl, score, embed, bounding_rect in zip(*dets):\n","            x, y, w, h = bounding_rect\n","            x = max(0, x)\n","            y = max(0, y)\n","            bbox = [x, y, w, h]\n","            detection_list.append(\n","                Detection(bbox, score, embed, class_name=cl, others=raw_polygon)\n","            )\n","        return detection_list\n","\n","    @staticmethod\n","    def process_polygons(raw_polygons):\n","        polygons = [\n","            [polygon[x : x + 2] for x in range(0, len(polygon), 2)]\n","            for polygon in raw_polygons\n","        ]\n","        bounding_rects = [\n","            cv2.boundingRect(np.array([polygon]).astype(int)) for polygon in polygons\n","        ]\n","        return polygons, bounding_rects\n","\n","    @staticmethod\n","    def crop_bb(frame, raw_dets, instance_masks=None):\n","        crops = []\n","        im_height, im_width = frame.shape[:2]\n","        if instance_masks is not None:\n","            masks = []\n","        else:\n","            masks = None\n","        for i, detection in enumerate(raw_dets):\n","            l, t, w, h = [int(x) for x in detection[0]]\n","            r = l + w\n","            b = t + h\n","            crop_l = max(0, l)\n","            crop_r = min(im_width, r)\n","            crop_t = max(0, t)\n","            crop_b = min(im_height, b)\n","            crops.append(frame[crop_t:crop_b, crop_l:crop_r])\n","            if instance_masks is not None:\n","                masks.append( instance_masks[i][crop_t:crop_b, crop_l:crop_r] )\n","\n","        return crops, masks\n","\n","    @staticmethod\n","    def crop_poly_pad_black(frame, polygons, bounding_rects):\n","        masked_polys = []\n","        im_height, im_width = frame.shape[:2]\n","        for polygon, bounding_rect in zip(polygons, bounding_rects):\n","            mask = np.zeros(frame.shape, dtype=np.uint8)\n","            polygon_mask = np.array([polygon]).astype(int)\n","            cv2.fillPoly(mask, polygon_mask, color=(255, 255, 255))\n","\n","            # apply the mask\n","            masked_image = cv2.bitwise_and(frame, mask)\n","\n","            # crop masked image\n","            x, y, w, h = bounding_rect\n","            crop_l = max(0, x)\n","            crop_r = min(im_width, x + w)\n","            crop_t = max(0, y)\n","            crop_b = min(im_height, y + h)\n","            cropped = masked_image[crop_t:crop_b, crop_l:crop_r].copy()\n","            masked_polys.append(np.array(cropped))\n","        return masked_polys\n","\n","    def delete_all_tracks(self):\n","        self.tracker.delete_all_tracks()\n"]}]}